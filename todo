**MVP Digital Twin**
Static datasets

- DWER Perth Stormwater Drainage pipes GIS database
- DWER Hydrographic Catchments/Subcatchments
- Historic rainfall events

Dynamic datasets

- BOM weather observations
- Google weather API forecasts
- Community reported flood issues

Outputs

- Catchment flood characteristics
- Flood risk for given coordinates from rainfall observations, rainfall forecast, pre-determined rainfall events (10 year, 100 year etc..) and custom rainfall event

Intergration to frontend

- Allow front end to query flood risk for device location based on rainfall observations, rainfall forecast, pre-determined rainfall events (10 year, 100 year etc..) and custom rainfall event

**Deployment Workflows** - Done

1. Dockerfile to configure mongoDB
2. init_db.py to apply schema and innitalise the database config
3. geojson_converter.py this generates the catchments_spatial_matched.json - this can probabally be done once and deployed with the codebase.
4. spatial_import.py imports rainfall events and spatial data into mongodb

**TODO**

**Digital Twin**
~~Review geojson_converter to confirm new geojson matching working~~
~~Rebuild database with new catchment structure~~
Update digital twin continuous monitoring mode to become always on monitoring tied to API service running

**Algorithm**
~~Review algorithm to check why always outputting risk = 1~~
Runoff Coefficient using default value for every catchment. review to update or calculate value per catchment - Pedro

**API**
~~Add authentication to endpoints~~
~~Debug risk endpoint returning - "detail": "No catchment found for provided point" - Given to Pedro~~

**Deployment**
~~Review resource requiements, likley double vps specs - Done~~
~~Should we deploy mongoDB in container? Yes - Done~~
~~Digital Twin service and api deployed in venv on VPS - Done~~

Update README and ensure code comments coverage

- visualise the digital twin output
